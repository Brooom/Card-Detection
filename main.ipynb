{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generation\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import cv2\n",
    "from library.img_rando import *\n",
    "\n",
    "# Train\n",
    "random.seed('train')\n",
    "PATH_ALL_IMAGES = '1_all_images/'\n",
    "CSV_NAME = '1_all_images/all_labels'\n",
    "\n",
    "# Set number of differnt iterations (min 1)\n",
    "zoom_data_size= 5\n",
    "rot_data_size = 3\n",
    "POV_data_size = 3\n",
    "pos_data_size = 3\n",
    "\n",
    "# import images and cvs\n",
    "path_cards = '0_cards_images'\n",
    "path_background = '0_background_images'\n",
    "\n",
    "# Create a list of all the card images\n",
    "print(\"#########################################\")\n",
    "print(\"Card Images:\")\n",
    "\n",
    "images = np.empty((len(glob.glob(path_cards+\"/*.png\")),400,257,3), dtype=\"uint8\")\n",
    "i=0\n",
    "for file in glob.glob(path_cards+\"/*.png\"):\n",
    "    img = cv2.imread(file)\n",
    "    img[img==0] = 1\n",
    "    images[i,:,:,:] = np.asarray(img)\n",
    "    # Print filename withou path and extension\n",
    "    filename = file.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    print(f\"{i}: {filename}\")\n",
    "    i+=1\n",
    "\n",
    "images = np.array(images)\n",
    "images[images[:,:,:,:]==0] = 1 # Image is  not allowed to have any 0 vales at the beginning\n",
    "\n",
    "print(\"#########################################\")\n",
    "print(\"Background Images:\")\n",
    "back_images = np.empty((len(glob.glob(path_background+\"/*.jpg\")),1000,1500,3), dtype=\"uint8\")\n",
    "i=0\n",
    "for file in glob.glob(path_background+\"/*.jpg\"):\n",
    "    back_img = cv2.imread(file)\n",
    "    if back_img.shape != (1000,1500,3):\n",
    "        back_img = cv2.resize(back_img, (1500, 1000))\n",
    "    back_images[i,:,:,:] = back_img\n",
    "    i+=1\n",
    "\n",
    "#Output some info\n",
    "print(f\"Backgrounds: {back_images.shape}\")\n",
    "print(f\"Number of imges to be generated per card: {zoom_data_size* rot_data_size* POV_data_size*pos_data_size*3}\")\n",
    "print(f\"Number of images to be generated in total: {zoom_data_size* rot_data_size* POV_data_size*pos_data_size*3*images.shape[0]}\")\n",
    "labels = np.array([('filename','width','height','class','xmin','ymin','xmax','ymax')])\n",
    "count = 0\n",
    "\n",
    "# Generate Data\n",
    "\n",
    "start = time.time()\n",
    "#print(PATH_ALL_IMAGES)\n",
    "for img, index in zip(images,range(0,images.shape[0])):\n",
    "\n",
    "    print(\"img_\" ,index)\n",
    "\n",
    "    for i_zoom in range(zoom_data_size):\n",
    "        img_zoom = img_zoom_rand(img, maxZoom=2.1)\n",
    "        #cv2.imshow(\"img_zoom\", img_zoom)\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "        for i_rot in range(rot_data_size):\n",
    "            img_rot = img_rot_rand(img_zoom)\n",
    "            #cv2.imshow(\"img_rot\", img_rot)\n",
    "            #cv2.waitKey(0)\n",
    "\n",
    "            for i_pov in range(POV_data_size):\n",
    "                img_pov = img_3D_rand(img_rot)\n",
    "                #cv2.imshow(\"img_pov\", img_pov)\n",
    "                #cv2.waitKey(0)\n",
    "                for i_pos in range(pos_data_size):\n",
    "                    rand=randint(0,back_images.shape[0]-1)\n",
    "                    back = back_images[rand,:,:,:]     \n",
    "                    img_pos,pos = img_pos_rand(img_pov,back)\n",
    "                    #cv2.imshow(\"img_pos\", img_pos)\n",
    "                    #cv2.waitKey(0)\n",
    "\n",
    "                    for kernel_size in [1,3,5]:\n",
    "                        final_img=img_blure(img_pos,kernel_size)\n",
    "\n",
    "                        img_pov_color=img_pov.copy()\n",
    "                        img_pov_gray=cv2.cvtColor(img_pov, cv2.COLOR_BGR2GRAY)\n",
    "                        contours, hierarchy=cv2.findContours(img_pov_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "                        rect=cv2.boundingRect(contours[0])\n",
    "\n",
    "                        #cv2.imshow(\"final_img\", (final_img*255).astype(np.uint8))\n",
    "                        #cv2.waitKey(0)\n",
    "\n",
    "                        #save image\n",
    "                        print(PATH_ALL_IMAGES+'img_'+str(index).rjust(2,\"0\")+\"_\"+str(count).rjust(6,\"0\")+\".png\")\n",
    "                        cv2.imwrite(PATH_ALL_IMAGES+'img_'+str(index).rjust(2,\"0\")+\"_\"+str(count).rjust(6,\"0\")+\".png\",(final_img*255).astype(np.uint8))\n",
    "                        labels=np.append(labels,[('img_'+str(index).rjust(2,\"0\")+\"_\"+str(count).rjust(6,\"0\")+\".png\",\n",
    "                                                            final_img.shape[1],final_img.shape[0],index,pos[0]+rect[0],pos[1]+rect[1],rect[0]+rect[2]+pos[0],rect[1]+rect[3]+pos[1])],0)\n",
    "                        count += 1\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Total time taken: {round(end-start)}s\")\n",
    "\n",
    "# Save labels\n",
    "np.savetxt(CSV_NAME+\".csv\", labels, delimiter=\",\",fmt='%s')\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "data=pd.read_csv('1_all_images/all_labels.csv')\n",
    "PATH='1_all_images/'\n",
    "\n",
    "print(\"Nr of images: \", len(data))\n",
    "for i in range(len(data)):\n",
    "    label=[] #class center_x center_y width height - every mesurement is relative to the image size\n",
    "    print(i)\n",
    "    img_class = data.iloc[i]['class']\n",
    "    center_x = (data.iloc[i]['xmin']+data.iloc[i]['xmax'])/2\n",
    "    center_y = (data.iloc[i]['ymin']+data.iloc[i]['ymax'])/2\n",
    "    img_width = data.iloc[i]['width']\n",
    "    img_height = data.iloc[i]['height']\n",
    "    label=np.append(label,[img_class, round(center_x/img_width,5), round(center_y/img_height,5), round((data.iloc[i]['xmax']-data.iloc[i]['xmin'])/img_width,5), round((data.iloc[i]['ymax']-data.iloc[i]['ymin'])/img_height,5)])\n",
    "    np.savetxt(PATH+data.iloc[i]['filename'][0:-4]+\".txt\", label, newline=\" \",fmt='%s')\n",
    "    #img = cv2.imread(PATH+data.iloc[i]['filename'])\n",
    "    #cv2.rectangle(img,(int(data.iloc[i]['xmin']),int(data.iloc[i]['ymin'])),(int(data.iloc[i]['xmax']),int(data.iloc[i]['ymax'])),(0,255,0),2)\n",
    "    #print(label)\n",
    "    #cv2.imshow('img',img)\n",
    "    #cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test validation split\n",
    "import os\n",
    "import fnmatch\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "all_images = '1_all_images/'\n",
    "path_train = '2_splited_data/train/'\n",
    "path_test = '2_splited_data/test/'\n",
    "path_validation = '2_splited_data/validation/'\n",
    "image_datatypes = ['jpg', 'png', 'jpeg', 'bmp']\n",
    "nr_train= 0\n",
    "nr_test= 0\n",
    "nr_validation= 0\n",
    "\n",
    "# Check if the train folder exists\n",
    "if not os.path.exists(path_train):\n",
    "    os.makedirs(path_train)\n",
    "\n",
    "for root, dir, files in os.walk(path_train):\n",
    "    if files != []:\n",
    "        raise Exception(\"Train folder is not empty.\")\n",
    "\n",
    "# Check if the test folder exists\n",
    "if not os.path.exists(path_test):\n",
    "    os.makedirs(path_test)\n",
    "\n",
    "for root, dir, files in os.walk(path_test):\n",
    "    if files != []:\n",
    "        raise Exception(\"Test folder is not empty.\")\n",
    "\n",
    "# Check if the validation folder exists\n",
    "if not os.path.exists(path_validation):\n",
    "    os.makedirs(path_validation)\n",
    "\n",
    "for root, dir, files in os.walk(path_validation):\n",
    "    if files != []:\n",
    "        raise Exception(\"Validation folder is not empty.\")\n",
    "\n",
    "for root, dir, files in os.walk(all_images):\n",
    "    for items in fnmatch.filter(files, \"*\"):\n",
    "        if items[-3:len(items)] in image_datatypes:\n",
    "            random_number = random.random()\n",
    "            print(path_train+items)\n",
    "            print(path_train+items[0:-4]+\".txt\")\n",
    "            if 0 < random_number < 0.7:\n",
    "                shutil.move(all_images+items, path_train+items)\n",
    "                shutil.move(all_images+items[0:-4]+\".txt\", path_train+items[0:-4]+\".txt\")\n",
    "                nr_train += 1\n",
    "\n",
    "            elif 0.7 < random_number < 0.85:\n",
    "                shutil.move(all_images+items, path_validation+items)\n",
    "                shutil.move(all_images+items[0:-4]+\".txt\", path_validation+items[0:-4]+\".txt\")\n",
    "                nr_validation += 1\n",
    "\n",
    "            else:\n",
    "                shutil.move(all_images+items, path_test+items)\n",
    "                shutil.move(all_images+items[0:-4]+\".txt\", path_test+items[0:-4]+\".txt\")\n",
    "                nr_test += 1\n",
    "\n",
    "print(f\"Number of train images: {nr_train}\")\n",
    "print(f\"Number of test images: {nr_test}\")\n",
    "print(f\"Number of validation images: {nr_validation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import cv2\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #torch.cuda.empty_cache()\n",
    "    free_gpu_cache()\n",
    "    \n",
    "    # Load a model\n",
    "    model = YOLO('yolov10n.pt')  # Load pretrained model\n",
    "\n",
    "    # Train the model\n",
    "    model.train(data=\"2_splited_data/dataset.yaml\", epochs=40, batch=16, imgsz=640, pretrained=True, single_cls=False, patience=5, dropout=0.1, verbose=True, device=0, save_period=2)\n",
    "\n",
    "    # Validate the model\n",
    "    metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "    metrics.box.map    # map50-95\n",
    "    metrics.box.map50  # map50\n",
    "    metrics.box.map75  # map75\n",
    "    metrics.box.maps   # a list contains map50-95 of each category\n",
    "\n",
    "    print(model.names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
